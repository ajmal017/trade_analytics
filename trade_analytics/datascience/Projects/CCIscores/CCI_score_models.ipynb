{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MYPROJECT = '../../../'\n",
    "import os, sys\n",
    "sys.path.insert(0, MYPROJECT)\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"local_settings.py\")\n",
    "import django\n",
    "django.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The finance module has been deprecated in mpl 2.0 and will be removed in mpl 2.2. Please use the module mpl_finance instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter, WeekdayLocator,\\\n",
    "    DayLocator, MONDAY,date2num,num2date,AutoDateLocator\n",
    "from matplotlib.finance import quotes_historical_yahoo_ohlc, candlestick_ohlc,candlestick2_ochl,volume_overlay3\n",
    "\n",
    "from stockapp import models as stkmd\n",
    "from dataapp import models as dtamd\n",
    "from dataapp import tasks as dtatks\n",
    "from dataapp import libs as dtalibs\n",
    "\n",
    "from datascience import models as dtscmd\n",
    "from datascience import tasks as dtsctks\n",
    "from datascience import libs as dtsclibs\n",
    "\n",
    "from datascience import MLmodels as MLmd\n",
    "from datascience import MLlibs as MLlibs\n",
    "\n",
    "\n",
    "from featureapp import libs as ftlibs\n",
    "from featureapp import models as ftmd\n",
    "from stockapp import tasks as stktks\n",
    "from stockapp import libs as stklibs\n",
    "import featureapp.models as ftmd\n",
    "import featureapp.tasks as fttks\n",
    "import queryapp.models as qrymd\n",
    "import queryapp.tasks as qrytks\n",
    "\n",
    "import charts.chartservers.libs as chservlibs\n",
    "import charts.libs as chlibs\n",
    "\n",
    "\n",
    "import featureapp as ftapp\n",
    "import utility as uty\n",
    "from utility import models as utymd\n",
    "import itertools as itt\n",
    "import multiprocessing as mp\n",
    "from django.db import connection,connections\n",
    "from django.db import reset_queries\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "import imp\n",
    "import datetime\n",
    "from talib.abstract import *\n",
    "import utility.models as utmd\n",
    "import stockapp.libs as stklib\n",
    "from utility import codemanager as cdmng\n",
    "from utility import maintenance as mnt\n",
    "import os \n",
    "import json\n",
    "from django.contrib.auth.models import AnonymousUser\n",
    "import threading\n",
    "\n",
    "stk=stkmd.Stockmeta.objects.get(Symbol='TSLA')\n",
    "Fromdate=pd.datetime(2008,1,1)\n",
    "Todate=pd.datetime.today()\n",
    "Trange=pd.date_range(Fromdate,Todate)\n",
    "Trange=[T.date() for T in Trange if T.weekday()<=4]\n",
    "\n",
    "import json\n",
    "# fttks.computefeatuers(stk.id,Trange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D,Convolution1D,ZeroPadding1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import __version__ as keras_version\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import average_precision_score,accuracy_score,recall_score,precision_score\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.layers.pooling import AveragePooling1D\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import pdb\n",
    "\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn import linear_model,decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score,r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression,SGDClassifier\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "from scipy.sparse import coo_matrix, hstack ,vstack\n",
    "\n",
    "import gc\n",
    "\n",
    "print(gc.collect())\n",
    "\n",
    "import xgboost as xgb\n",
    "from keras import applications\n",
    "import os\n",
    "\n",
    "\n",
    "# deep models\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "import json\n",
    "import multiprocessing as mltproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# data=np.load('/media/venkat/BigDrive/training/train_TSLA.npz')\n",
    "pp='/media/venkat/BigDrive/training/'\n",
    "ff=os.listdir(pp)\n",
    "Xtrain=None\n",
    "for i in range(50):\n",
    "    print ff[i]\n",
    "    data=np.load(pp+ff[i])\n",
    "    if Xtrain==None:\n",
    "        Xtrain=data['Xtrain']\n",
    "        Ytrain=data['Ytrain']\n",
    "#         Y=(np.abs(Ytrain[:,3]/(Ytrain[:,0]+0.1) )).reshape(-1,1)\n",
    "    else:\n",
    "        Xtrain=np.vstack( (Xtrain,data['Xtrain']) )\n",
    "        Ytrain=np.vstack( (Ytrain,data['Ytrain']) )\n",
    "#         y=(np.abs(Ytrain[:,3]/(Ytrain[:,0]+0.1) ) ).reshape(-1,1)\n",
    "#         Y=np.vstack((Y, y ))\n",
    "        \n",
    "for i in range(Xtrain.shape[0]):\n",
    "    Xtrain[i,:,0:4]=Xtrain[i,:,0:4]-Xtrain[i,:,0:4].min()    \n",
    "    Xtrain[i,:,0:4]=Xtrain[i,:,0:4]/Xtrain[i,:,0:4].max()\n",
    "    \n",
    "    Xtrain[i,:,4]=Xtrain[i,:,4]-Xtrain[i,:,4].min()    \n",
    "    Xtrain[i,:,4]=Xtrain[i,:,4]/Xtrain[i,:,4].max()\n",
    "\n",
    "ind=(Ytrain[:,3]>=5) & (Ytrain[:,0]>=-2)\n",
    "Y=np.ones((Ytrain.shape[0],1))*-1\n",
    "Y[ind]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(Ytrain[:,3],bins=range(1,100,5))\n",
    "plt.hist(Ytrain[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "nb_epoch = 200\n",
    "random_state = 51\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding1D(padding=2, input_shape=(360,5) ) )\n",
    "model.add(Convolution1D(100, 20, strides=1, activation='relu'))\n",
    "model.add(ZeroPadding1D(padding=2 ) )\n",
    "model.add(Convolution1D(60, 10, strides=1, activation='relu'))\n",
    "model.add(AveragePooling1D(pool_size=3, strides=None, padding='valid'))\n",
    "\n",
    "model.add(ZeroPadding1D(padding=2 ) )\n",
    "model.add(Convolution1D(25, 8, strides=1, activation='relu'))\n",
    "model.add(ZeroPadding1D(padding=2 ) )\n",
    "model.add(Convolution1D(8, 5, strides=1, activation='relu'))\n",
    "model.add(AveragePooling1D(pool_size=3, strides=None, padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, init='normal'))\n",
    "\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam')\n",
    "\n",
    "\n",
    "model.fit(Xtrain, Y, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "      shuffle=True, verbose=1, validation_split=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xflat=np.zeros((Xtrain.shape[0],30*5))\n",
    "for i in range(Xtrain.shape[0]):\n",
    "    Xflat[i,:]=Xtrain[i,-30:,:].reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=np.hstack((Xflat,Y)),columns=list(range(Xflat.shape[1]))+['out'] )\n",
    "nump=len(df[df['out']==1])\n",
    "numm=len(df[df['out']==-1])\n",
    "print numm,nump\n",
    "dm=df[df['out']==-1].iloc[np.random.choice(numm,nump) ]\n",
    "\n",
    "da=pd.concat( [df[df['out']==1],dm   ]  )\n",
    "Xmod=da[ [cc for cc in da.columns if cc!='out'] ].values\n",
    "Ymod=da['out'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xmod, Ymod, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=200,min_samples_leaf=10,verbose=1,n_jobs=2 ,max_features='auto')\n",
    "rf.fit(X_train,y_train)\n",
    "ypred=rf.predict(X_train)\n",
    "rf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred=rf.predict(Xflat)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yprob=rf.predict_proba(Xflat)\n",
    "yprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj=dtscmd.Project(Name='CCIscores',Misc={})\n",
    "proj.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, {u'datascience.MLmodels': 0, u'datascience.Project': 1})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtscmd.Project.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RawProcessedData= dtscmd.Data(Project=proj,GroupName='WindowData_Perf',tag='',Modeltype='Regression',Datatype='RawProcessed',Dataformat='joblib')\n",
    "RawProcessedData.save()\n",
    "RawProcessedData.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QuerySet [<Data: CCIscores WindowData_Perf  Regression RawProcessed joblib>]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Data: CCIscores WindowData_Perf  Regression RawProcessed joblib>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print dtscmd.Data.objects.all()\n",
    "RawProcessedData=dtscmd.Data.objects.all()[0]\n",
    "RawProcessedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RawProcessedData.ShardInfo={}\n",
    "RawProcessedData.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6115 6116 16 6116   6116  6116  6116   6116    6116  6116  6116  6116 6116  6116  6116 6116  6116  6116 6116 6116  6116   6116 6116  6116 6116  6116   6116  6116  6116  6116 6116  6116  6116 6116  6116      6116  6116  6116  6116  6116  6116 6116  6116  6116  6116  6116  6116 6116  6116 6116  6116 6116  6116  6116  6116   6116  6116  6116  6116  6116   6116  6116  6116  6116  6116  6116  6116  6116  6116 6116  6116 6116  6116   6116  6116     6116  6116  6116  6116  6116  6116  6116  6116  6116 6116 6116 6116 6116 6116 6116 6116  6116 6116  6116  6116  6116  6116  6116  6116     6116  6116 6116    \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 268, in _feed\n",
      "    send(obj)\n",
      "IOError: [Errno 32] Broken pipe\n",
      "Process Process-7:\n",
      "    time.sleep(0.3)\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-8-164dc87ffa84>\", line 15, in saveff\n",
      "  File \"<ipython-input-8-164dc87ffa84>\", line 15, in saveff\n",
      "    time.sleep(0.3)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-164dc87ffa84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# ev.set()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/process.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0m_current_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/forking.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mdeadline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/forking.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import multiprocessing as mp\n",
    "import Queue\n",
    "import time\n",
    "\n",
    "def saveff(INQ,ev):\n",
    "    while True:\n",
    "        try:\n",
    "            rf,path=INQ.get_nowait()\n",
    "            data=np.load(rf)\n",
    "            with open(path,'w') as F:\n",
    "                joblib.dump({'X':data['Xtrain'],'Y':data['Ytrain']},F,compress=3)\n",
    "        except Queue.Empty:\n",
    "            break\n",
    "        \n",
    "        if ev.is_set():\n",
    "            print \"breaking\"\n",
    "            break\n",
    "            \n",
    "            \n",
    "INQ=mp.Queue()\n",
    "ev=mp.Event()\n",
    "ev.clear()\n",
    "P=[]\n",
    "for i in range(2):\n",
    "    P.append( mp.Process(target=saveff,args=(INQ,ev)) )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "pp='/media/venkat/BigDrive/training/'\n",
    "ff=os.listdir(pp)\n",
    "Xtrain=None\n",
    "for i in range(len(ff)):\n",
    "    print i,len(ff),\"\\r\",\n",
    "#     data=np.load(pp+ff[i])\n",
    "    name,path=RawProcessedData.newshardpath()\n",
    "    INQ.put( (pp+ff[i],path) )\n",
    "    time.sleep(0.01)\n",
    "    \n",
    "#     with open(path,'w') as F:\n",
    "#         joblib.dump({'X':data['Xtrain'],'Y':data['Ytrain']},F,compress=3)\n",
    "\n",
    "for p in P:\n",
    "    p.start()\n",
    "    \n",
    "# ev.set()\n",
    "for p in P:\n",
    "    p.join()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
