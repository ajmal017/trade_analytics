{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/django/db/models/base.py:324: RuntimeWarning: Model 'datascience.label' was already registered. Reloading models is not advised as it can lead to inconsistencies, most notably with related models.\n",
      "  new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n",
      "/usr/local/lib/python2.7/dist-packages/django/db/models/base.py:324: RuntimeWarning: Model 'datascience.computefunc' was already registered. Reloading models is not advised as it can lead to inconsistencies, most notably with related models.\n",
      "  new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n",
      "/usr/local/lib/python2.7/dist-packages/django/db/models/base.py:324: RuntimeWarning: Model 'datascience.project' was already registered. Reloading models is not advised as it can lead to inconsistencies, most notably with related models.\n",
      "  new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n",
      "/usr/local/lib/python2.7/dist-packages/django/db/models/base.py:324: RuntimeWarning: Model 'datascience.data' was already registered. Reloading models is not advised as it can lead to inconsistencies, most notably with related models.\n",
      "  new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n",
      "/usr/local/lib/python2.7/dist-packages/django/db/models/base.py:324: RuntimeWarning: Model 'datascience.mlmodels' was already registered. Reloading models is not advised as it can lead to inconsistencies, most notably with related models.\n",
      "  new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n",
      "/usr/local/lib/python2.7/dist-packages/django/db/models/base.py:324: RuntimeWarning: Model 'datascience.modelmetrics' was already registered. Reloading models is not advised as it can lead to inconsistencies, most notably with related models.\n",
      "  new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named talib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-73e8e2019a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstockapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstkmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtamd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtatks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtalibs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfeatureapp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mftlibs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/venkat/n.adurthi@gmail.com/repos/trade_analytics/trade_analytics/dataapp/tasks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelcomputations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mitt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdataapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtalibs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# make the function shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/venkat/n.adurthi@gmail.com/repos/trade_analytics/trade_analytics/dataapp/libs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtalib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaintenance\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named talib"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter, WeekdayLocator,\\\n",
    "    DayLocator, MONDAY,date2num,num2date,AutoDateLocator\n",
    "from matplotlib.finance import quotes_historical_yahoo_ohlc, candlestick_ohlc,candlestick2_ochl,volume_overlay3\n",
    "\n",
    "from stockapp import models as stkmd\n",
    "from dataapp import models as dtamd\n",
    "from dataapp import tasks as dtatks\n",
    "from dataapp import libs as dtalibs\n",
    "from featureapp import libs as ftlibs\n",
    "from featureapp import models as ftmd\n",
    "from stockapp import tasks as stktks\n",
    "from stockapp import libs as stklibs\n",
    "import featureapp.models as ftmd\n",
    "import featureapp.tasks as fttks\n",
    "import queryapp.models as qrymd\n",
    "import queryapp.tasks as qrytks\n",
    "\n",
    "import charts.chartservers.libs as chservlibs\n",
    "import charts.libs as chlibs\n",
    "\n",
    "from datascience import models as dtscmd\n",
    "from datascience import tasks as dtsctks\n",
    "from datascience import libs as dtsclibs\n",
    "\n",
    "\n",
    "import featureapp as ftapp\n",
    "import utility as uty\n",
    "from utility import models as utymd\n",
    "import itertools as itt\n",
    "import multiprocessing as mp\n",
    "from django.db import connection,connections\n",
    "from django.db import reset_queries\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "import imp\n",
    "import datetime\n",
    "from talib.abstract import *\n",
    "import utility.models as utmd\n",
    "import stockapp.libs as stklib\n",
    "from utility import codemanager as cdmng\n",
    "from utility import maintenance as mnt\n",
    "import os \n",
    "import json\n",
    "from django.contrib.auth.models import AnonymousUser\n",
    "import threading\n",
    "\n",
    "stk=stkmd.Stockmeta.objects.get(Symbol='TSLA')\n",
    "Fromdate=pd.datetime(2008,1,1)\n",
    "Todate=pd.datetime.today()\n",
    "Trange=pd.date_range(Fromdate,Todate)\n",
    "Trange=[T.date() for T in Trange if T.weekday()<=4]\n",
    "\n",
    "import json\n",
    "# fttks.computefeatuers(stk.id,Trange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to charting server\n",
      "received dataframe\n"
     ]
    }
   ],
   "source": [
    "entries=[\n",
    "    {'Symbol':'TSLA','TF':pd.datetime(2012,1,1).date(),'T0':pd.datetime(2011,1,1).date()  },\n",
    "    {'Symbol':'AAPL','TF':pd.datetime(2012,1,1).date(),'T0':pd.datetime(2011,1,1).date()  }\n",
    "]\n",
    "chservlibs.request_db_charts(entries,5003)\n",
    "# img=chlibs.CurrentByFutureChart_bydb(entries[0]['T0'],entries[0]['TF'],entries[0]['Symbol'],indicatorlist=(),pricecols=(),querycols=(),featcols=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Running Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"---------------- features-------------------\"\n",
    "featurecodes=ftmd.FeatureComputeCode.objects.all()\n",
    "computecode=featurecodes[0]\n",
    "computeclass=computecode.importcomputeclass()\n",
    "CF=computeclass(stk.id,Trange)\n",
    "CF.computeall(skipdone=True)\n",
    "# CF.saveall()\n",
    "print CF.getfeaturelist()\n",
    "\n",
    "CF.df=CF.addindicators(CF.df,[\n",
    "        {'name':'SMAstd','timeperiod':20,'colname':'SMAstd20'},\n",
    "        {'name':'EMAstd','timeperiod':8,'colname':'EMAstd8'},\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "querycodes=qrymd.QueryComputeCode.objects.all()\n",
    "computecode=querycodes[0]\n",
    "computeclass=computecode.importcomputeclass()\n",
    "CQ=computeclass(stk.id,Trange)\n",
    "CQ.computeall(skipdone=True)\n",
    "CQ.saveall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CQ.OutcomeCharts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CQ.getquerylist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CQ.chartfeatures(addpricecols=(),ip=5562,\n",
    "addfeatcols=[\n",
    "    ['CCI5','CCI50'],\n",
    "    ['PastPROFIT10days','PastLOSS10days'],['FutPROFIT10days','FutLOSS10days']\n",
    "],\n",
    "addquerycols=[\n",
    "    'CCICHERRIES',\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name,path=RawData.newshardpath()\n",
    "with open(path,'w') as F:\n",
    "    joblib.dump({},F,compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cloudpickle as cldpkl\n",
    "\n",
    "class foo(object):\n",
    "    x=1\n",
    "    def f1(self,a):\n",
    "        print \"f1\"\n",
    "        return a+self.x\n",
    "class goo(foo):\n",
    "    y=2\n",
    "    def f2(self,b):\n",
    "        print \"f2\"\n",
    "        return b+self.y+self.x\n",
    "with open(\"test.pkl\",'w') as F:\n",
    "    cldpkl.dump(goo,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_id=register_dataset(\n",
    "    project_Name=\"PredictReturn_TSLA\", \n",
    "    create_project_ifnotexists=True,\n",
    "    project_Info={'description': \"Testing the algorithms on TSLA to predict next 10 day return \\n\"+\n",
    "                                 \"Data taken on every Friday\"},\n",
    "    GroupName=\"Fullstocktime\",\n",
    "    tag=\"1\",\n",
    "    Datatype='RawProcessed',\n",
    "    data_format='npz',\n",
    "    Modeltype='Regression',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @register_func(overwrite_if_exists=False)\n",
    "def extractdataset(data_id,Symbol):\n",
    "    window=60\n",
    "    window_fut=30\n",
    "    Tfs=map(lambda x: ( (x.date()-pd.Dateoffset(window)).date(),x.date(), (x.date()+pd.Dateoffset(window_fut)).date() ),\n",
    "            pd.date_range(start=pd.datetime(2010,1,1),end=pd.datetime.today(),freq='W-MON') )\n",
    "    \n",
    "    N=len(Tfs)\n",
    "    dfinstants=pd.DataFrame({'T0':map(lambda x: x[0],Tfs),'TF':map(lambda x: x[1],Tfs),'Symbol':[Symbol]*N})\n",
    "    X,X_Meta=dtalibs.Getbatchdata(dfinstants)\n",
    "    \n",
    "    dfinstants=pd.DataFrame({'T0':map(lambda x: x[1],Tfs),'TF':map(lambda x: x[2],Tfs),'Symbol':[Symbol]*N})\n",
    "    Y,Y_Meta=dtalibs.Getbatchdata(dfinstants)\n",
    "    \n",
    "    shard=dtscmd.DataShard(Data__id=data_id)\n",
    "    shard.Info['X_Meta']=X_Meta\n",
    "    shard.Info['Y_Meta']=Y_Meta\n",
    "    shard.save()\n",
    "    \n",
    "    np.savez_compressed(shard.shardpath(),X=X,Y=Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras.models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-33789c8cb226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcloudpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcldpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatascience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mML\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mMLmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/venkat/n.adurthi@gmail.com/repos/trade_analytics/trade_analytics/datascience/ML/MLmodels.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m####################   KERAS  #####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras.models"
     ]
    }
   ],
   "source": [
    "import cloudpickle as cldpkl\n",
    "import datascience.ML.MLmodels as MLmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name np_utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c74e2bd4ca71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name np_utils"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
